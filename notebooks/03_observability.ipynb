{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Observability & Tracing\n",
    "\n",
    "This notebook explores TensorZero's observability features:\n",
    "- Understanding inference data stored in ClickHouse\n",
    "- Using the TensorZero UI for monitoring\n",
    "- Implementing feedback loops\n",
    "- Analyzing performance metrics\n",
    "- Testing structured outputs with advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tensorzero import TensorZeroGateway\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize gateway client with new method\n",
    "client = TensorZeroGateway.build_http(\"http://localhost:3000\")\n",
    "print(\"‚úÖ Connected to TensorZero gateway\")\n",
    "print(\"üåê TensorZero UI: http://localhost:4000\")\n",
    "print(\"üìä ClickHouse: http://localhost:8123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Test Data\n",
    "\n",
    "Let's generate some inference data across different providers to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scenarios for observability\n",
    "test_prompts = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain quantum computing briefly.\",\n",
    "    \"How does blockchain work?\",\n",
    "    \"What is cloud computing?\",\n",
    "    \"Describe artificial intelligence.\"\n",
    "]\n",
    "\n",
    "# Providers to test\n",
    "providers_to_test = [\n",
    "    (\"gpt4_mini\", \"OpenAI GPT-4o Mini\"),\n",
    "    (\"claude3_haiku\", \"Anthropic Claude 3 Haiku\"),\n",
    "    (\"grok3_mini\", \"xAI Grok-3 Mini\"),\n",
    "]\n",
    "\n",
    "# Generate test data\n",
    "inference_ids = []\n",
    "\n",
    "print(\"üß™ Generating test data...\")\n",
    "for prompt in test_prompts:\n",
    "    for variant, provider_name in providers_to_test:\n",
    "        try:\n",
    "            response = client.inference(\n",
    "                function_name=\"chat\",\n",
    "                variant_name=variant,\n",
    "                input={\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            inference_ids.append({\n",
    "                \"inference_id\": response.inference_id,\n",
    "                \"variant\": variant,\n",
    "                \"provider\": provider_name,\n",
    "                \"prompt\": prompt,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            print(f\"‚úÖ {provider_name}: {prompt[:30]}... - ID: {response.inference_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {provider_name}: {prompt[:30]}... - Error: {str(e)[:50]}\")\n",
    "\n",
    "print(f\"\\nüìä Generated {len(inference_ids)} successful inferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecting Feedback\n",
    "\n",
    "TensorZero allows collecting feedback on inferences for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect feedback on some inferences\n",
    "import random\n",
    "\n",
    "print(\"üìù Collecting feedback on inferences...\")\n",
    "\n",
    "# Sample some inference IDs for feedback\n",
    "feedback_samples = random.sample(inference_ids, min(5, len(inference_ids)))\n",
    "\n",
    "for sample in feedback_samples:\n",
    "    # Simulate different types of feedback\n",
    "    feedback_score = random.uniform(0.5, 1.0)\n",
    "    helpful = feedback_score > 0.7\n",
    "    \n",
    "    try:\n",
    "        client.feedback(\n",
    "            inference_id=sample[\"inference_id\"],\n",
    "            feedback={\n",
    "                \"score\": feedback_score,\n",
    "                \"helpful\": helpful,\n",
    "                \"provider\": sample[\"provider\"],\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Feedback for {sample['provider']}: Score={feedback_score:.2f}, Helpful={helpful}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to submit feedback: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Direct ClickHouse Queries\n",
    "\n",
    "Let's query ClickHouse directly to analyze our inference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClickHouse connection details\n",
    "clickhouse_url = \"http://localhost:8123\"\n",
    "clickhouse_user = \"chuser\"\n",
    "clickhouse_password = \"chpassword\"\n",
    "database = \"tensorzero\"\n",
    "\n",
    "def query_clickhouse(query):\n",
    "    \"\"\"Execute a query against ClickHouse.\"\"\"\n",
    "    response = httpx.post(\n",
    "        f\"{clickhouse_url}/\",\n",
    "        params={\n",
    "            \"database\": database,\n",
    "            \"user\": clickhouse_user,\n",
    "            \"password\": clickhouse_password,\n",
    "            \"default_format\": \"JSONEachRow\"\n",
    "        },\n",
    "        data=query\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        lines = response.text.strip().split('\\n')\n",
    "        return [json.loads(line) for line in lines if line]\n",
    "    else:\n",
    "        raise Exception(f\"ClickHouse query failed: {response.text}\")\n",
    "\n",
    "# Test ClickHouse connection\n",
    "try:\n",
    "    tables = query_clickhouse(\"SHOW TABLES\")\n",
    "    print(\"üìä ClickHouse Tables:\")\n",
    "    for table in tables:\n",
    "        print(f\"   ‚Ä¢ {table['name']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ClickHouse connection error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query recent inferences\n",
    "try:\n",
    "    # Get inference count by variant\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        variant_name,\n",
    "        COUNT(*) as count,\n",
    "        AVG(inference_duration_ms) as avg_duration_ms\n",
    "    FROM Chat_inferences\n",
    "    WHERE timestamp > now() - INTERVAL 1 HOUR\n",
    "    GROUP BY variant_name\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    results = query_clickhouse(query)\n",
    "    \n",
    "    if results:\n",
    "        print(\"üìà Inference Statistics (Last Hour):\")\n",
    "        print(\"=\" * 50)\n",
    "        for row in results:\n",
    "            print(f\"Variant: {row['variant_name']}\")\n",
    "            print(f\"  Count: {row['count']}\")\n",
    "            print(f\"  Avg Duration: {row.get('avg_duration_ms', 'N/A')} ms\\n\")\n",
    "    else:\n",
    "        print(\"No inference data found in the last hour\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Query error: {e}\")\n",
    "    # Let's try to see what tables actually exist\n",
    "    try:\n",
    "        tables = query_clickhouse(\"SHOW TABLES\")\n",
    "        print(\"\\nAvailable tables:\")\n",
    "        for table in tables:\n",
    "            print(f\"  ‚Ä¢ {table['name']}\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Output Testing\n",
    "\n",
    "Let's test structured outputs, especially with Grok models that support this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check if we have a structured output function configured\n",
    "# If not, we'll create one\n",
    "\n",
    "print(\"üîß Testing Structured Output Capabilities\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test with sentiment analysis (if configured)\n",
    "test_texts = [\n",
    "    \"TensorZero is amazing! It makes LLM integration so easy.\",\n",
    "    \"The setup was a bit complex but worth it.\",\n",
    "    \"Having issues with the configuration.\"\n",
    "]\n",
    "\n",
    "# Try sentiment analysis if available\n",
    "try:\n",
    "    for text in test_texts:\n",
    "        response = client.inference(\n",
    "            function_name=\"analyze_sentiment\",\n",
    "            variant_name=\"gpt4_json\",  # Try with GPT-4 first\n",
    "            input={\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Parse structured output\n",
    "        result = json.loads(response.content[0].text)\n",
    "        \n",
    "        print(f\"\\nText: '{text[:50]}...'\")\n",
    "        print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.2f})\")\n",
    "        print(f\"Explanation: {result['explanation']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Sentiment analysis not configured or failed: {str(e)[:100]}\")\n",
    "    print(\"\\nTo enable structured output, add this to your tensorzero.toml:\")\n",
    "    print(\"\"\"[functions.analyze_sentiment]\n",
    "type = \"json\"\n",
    "schema = '''{\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "    \"confidence\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    \"explanation\": {\"type\": \"string\"}\n",
    "  },\n",
    "  \"required\": [\"sentiment\", \"confidence\", \"explanation\"]\n",
    "}'''\n",
    "\n",
    "[functions.analyze_sentiment.variants.grok3_mini]\n",
    "type = \"chat_completion\"\n",
    "model = \"xai::grok-3-mini\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis Dashboard\n",
    "\n",
    "Let's create a simple performance dashboard using the data we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a performance summary\n",
    "if inference_ids:\n",
    "    df = pd.DataFrame(inference_ids)\n",
    "    \n",
    "    print(\"üìä Inference Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Count by provider\n",
    "    provider_counts = df['provider'].value_counts()\n",
    "    print(\"\\nInferences by Provider:\")\n",
    "    for provider, count in provider_counts.items():\n",
    "        print(f\"  {provider}: {count}\")\n",
    "    \n",
    "    # Recent activity\n",
    "    print(f\"\\nTotal Inferences: {len(df)}\")\n",
    "    print(f\"Unique Prompts: {df['prompt'].nunique()}\")\n",
    "    print(f\"Time Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    \n",
    "    # Show sample IDs for UI exploration\n",
    "    print(\"\\nüîç Sample Inference IDs (for UI exploration):\")\n",
    "    for _, row in df.head(3).iterrows():\n",
    "        print(f\"  ‚Ä¢ {row['inference_id']} ({row['provider']})\")\n",
    "    \n",
    "    print(f\"\\nüåê View these in TensorZero UI: http://localhost:4000\")\n",
    "else:\n",
    "    print(\"‚ùå No inference data collected yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Observability Features\n",
    "\n",
    "Let's explore more advanced features like tracing multi-step workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step workflow example\n",
    "print(\"üîÑ Testing Multi-Step Workflow Tracing\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Step 1: Generate a topic\n",
    "try:\n",
    "    step1 = client.inference(\n",
    "        function_name=\"chat\",\n",
    "        variant_name=\"gpt4_mini\",\n",
    "        input={\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": \"Generate a random technical topic in 3 words or less.\"}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    topic = step1.content[0].text\n",
    "    print(f\"Step 1 - Topic Generated: {topic}\")\n",
    "    print(f\"  Inference ID: {step1.inference_id}\")\n",
    "    \n",
    "    # Step 2: Explain the topic\n",
    "    step2 = client.inference(\n",
    "        function_name=\"chat\",\n",
    "        variant_name=\"claude3_haiku\",\n",
    "        input={\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": f\"Explain '{topic}' in one sentence.\"}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    explanation = step2.content[0].text\n",
    "    print(f\"\\nStep 2 - Explanation: {explanation}\")\n",
    "    print(f\"  Inference ID: {step2.inference_id}\")\n",
    "    \n",
    "    # Step 3: Generate a haiku about it\n",
    "    step3 = client.inference(\n",
    "        function_name=\"generate_haiku\",\n",
    "        input={\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": f\"Write a haiku about {topic}.\"}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    haiku = step3.content[0].text\n",
    "    print(f\"\\nStep 3 - Haiku:\\n{haiku}\")\n",
    "    print(f\"  Inference ID: {step3.inference_id}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Multi-step workflow completed!\")\n",
    "    print(\"View the trace in TensorZero UI to see how these steps connect.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Workflow failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Observability Features:\n",
    "1. **Inference Tracking**: Every API call gets a unique ID\n",
    "2. **Feedback Loop**: Can attach feedback to any inference\n",
    "3. **ClickHouse Storage**: All data queryable for analysis\n",
    "4. **UI Dashboard**: Visual exploration at http://localhost:4000\n",
    "\n",
    "### Advanced Capabilities:\n",
    "1. **Structured Output**: JSON schema validation (all Grok models support this)\n",
    "2. **Multi-Step Tracing**: Track complex workflows\n",
    "3. **Performance Metrics**: Latency, token usage, costs\n",
    "4. **A/B Testing**: Built-in experimentation framework\n",
    "\n",
    "### Next Steps:\n",
    "1. Explore the TensorZero UI for visual insights\n",
    "2. Set up custom ClickHouse queries for specific metrics\n",
    "3. Implement structured output functions\n",
    "4. Create feedback-driven optimization loops\n",
    "\n",
    "Next notebook: We'll explore prompt management and A/B testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}