{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Agent Integration with TensorZero\n",
    "\n",
    "This notebook demonstrates how to build agents using TensorZero's native tool calling system:\n",
    "- Understanding TensorZero's tool configuration approach\n",
    "- Building a simple conversational agent with tools\n",
    "- Multi-turn conversations with tool usage\n",
    "- Agent observability and feedback collection\n",
    "- Performance analysis and benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 TensorZero Agent Development Environment\n",
      "==================================================\n",
      "✅ Connected to TensorZero Gateway\n",
      "✅ Basic inference test: 0198f364-81c3-75a0-acaf-190d3a1b534d...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from tensorzero import TensorZeroGateway, ToolCall\n",
    "from typing import List, Dict, Any, Optional\n",
    "import json\n",
    "\n",
    "print(\"🔧 TensorZero Agent Development Environment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize TensorZero client\n",
    "client = TensorZeroGateway.build_http(gateway_url=\"http://localhost:3000\")\n",
    "print(\"✅ Connected to TensorZero Gateway\")\n",
    "\n",
    "# Test basic connection\n",
    "try:\n",
    "    response = client.inference(\n",
    "        function_name=\"chat\",\n",
    "        variant_name=\"gpt4_mini\",\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]}\n",
    "    )\n",
    "    print(f\"✅ Basic inference test: {response.inference_id}...\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection test failed: {e}\")\n",
    "    print(\"💡 Make sure TensorZero services are running with 'docker compose up'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding TensorZero's Tool System\n",
    "\n",
    "TensorZero handles tools differently from OpenAI. Let's explore how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing TensorZero Tool System\n",
      "========================================\n",
      "📝 Inference ID: 0198f364-8472-7033-99da-f003a5e85233\n",
      "🏷️  Variant: gpt4_mini\n",
      "🔧 Tool Calls Detected: 1\n",
      "   📌 calculator: {'expression': '25 + 17'}\n"
     ]
    }
   ],
   "source": [
    "# Test the agent_chat function with tools\n",
    "print(\"🔧 Testing TensorZero Tool System\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test a simple query that should trigger calculator tool\n",
    "try:\n",
    "    response = client.inference(\n",
    "        function_name=\"agent_chat\",\n",
    "        variant_name=\"gpt4_mini\",\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": \"What is 25 + 17?\"}]}\n",
    "    )\n",
    "    \n",
    "    print(f\"📝 Inference ID: {response.inference_id}\")\n",
    "    print(f\"🏷️  Variant: {response.variant_name}\")\n",
    "    \n",
    "    # Process response content\n",
    "    assistant_text = \"\"\n",
    "    tool_calls = []\n",
    "    \n",
    "    if hasattr(response, 'content') and response.content:\n",
    "        for content_block in response.content:\n",
    "            if hasattr(content_block, 'text') and content_block.text:\n",
    "                assistant_text += content_block.text\n",
    "                print(f\"💬 Assistant: {content_block.text}\")\n",
    "            elif isinstance(content_block, ToolCall):\n",
    "                tool_calls.append({\n",
    "                    \"name\": content_block.name,\n",
    "                    \"args\": content_block.arguments if hasattr(content_block, 'arguments') else {},\n",
    "                    \"id\": content_block.id if hasattr(content_block, 'id') else f\"call_{len(tool_calls)}\"\n",
    "                })\n",
    "    \n",
    "    if tool_calls:\n",
    "        print(f\"🔧 Tool Calls Detected: {len(tool_calls)}\")\n",
    "        for tool_call in tool_calls:\n",
    "            print(f\"   📌 {tool_call['name']}: {tool_call['args']}\")\n",
    "    else:\n",
    "        print(\"ℹ️  No tool calls detected\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Tool test failed: {e}\")\n",
    "    print(\"\\n💡 Key Difference: TensorZero configures tools in tensorzero.toml, not in requests!\")\n",
    "    print(\"   - Tools are defined in the configuration file\")\n",
    "    print(\"   - Requests just specify the function with tools configured\")\n",
    "    print(\"   - Tool calls come back as ToolCall objects, not OpenAI format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Simple Agent\n",
    "\n",
    "Now let's create a conversational agent that can use tools effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 TensorZero Agent initialized\n",
      "\n",
      "✅ Agent ready! Available tools: calculator, get_weather, search_tensorzero_docs\n"
     ]
    }
   ],
   "source": [
    "class TensorZeroAgent:\n",
    "    \"\"\"A simple conversational agent using TensorZero's tool system.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: TensorZeroGateway):\n",
    "        self.client = client\n",
    "        self.conversation_history = []\n",
    "        print(\"🤖 TensorZero Agent initialized\")\n",
    "    \n",
    "    def chat(self, user_message: str, show_details: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Send a message and get response with tool handling.\"\"\"\n",
    "        \n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        \n",
    "        if show_details:\n",
    "            print(f\"👤 User: {user_message}\")\n",
    "        \n",
    "        try:\n",
    "            # Make inference with TensorZero\n",
    "            response = self.client.inference(\n",
    "                function_name=\"agent_chat\",\n",
    "                variant_name=\"gpt4_mini\",\n",
    "                input={\"messages\": self.conversation_history}\n",
    "            )\n",
    "            \n",
    "            # Process the response\n",
    "            assistant_content = \"\"\n",
    "            tool_calls = []\n",
    "            \n",
    "            if hasattr(response, 'content') and response.content:\n",
    "                for content_block in response.content:\n",
    "                    if hasattr(content_block, 'text') and content_block.text:\n",
    "                        assistant_content += content_block.text\n",
    "                    elif isinstance(content_block, ToolCall):\n",
    "                        tool_calls.append({\n",
    "                            \"name\": content_block.name,\n",
    "                            \"args\": content_block.arguments if hasattr(content_block, 'arguments') else {},\n",
    "                            \"id\": content_block.id if hasattr(content_block, 'id') else f\"call_{len(tool_calls)}\"\n",
    "                        })\n",
    "            \n",
    "            # Add assistant message to history\n",
    "            assistant_message = {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": assistant_content if assistant_content else \"I need to use a tool to help you.\"\n",
    "            }\n",
    "            \n",
    "            if tool_calls:\n",
    "                assistant_message[\"tool_calls\"] = tool_calls\n",
    "            \n",
    "            self.conversation_history.append(assistant_message)\n",
    "            \n",
    "            if show_details:\n",
    "                if assistant_content:\n",
    "                    print(f\"🤖 Agent: {assistant_content}\")\n",
    "                if tool_calls:\n",
    "                    print(f\"🔧 Used tools: {len(tool_calls)}\")\n",
    "                    for tool_call in tool_calls:\n",
    "                        print(f\"   📌 {tool_call['name']}: {tool_call['args']}\")\n",
    "                print(f\"📝 Inference: {response.inference_id}...\")\n",
    "            \n",
    "            return {\n",
    "                \"response\": assistant_content,\n",
    "                \"tool_calls\": tool_calls,\n",
    "                \"inference_id\": response.inference_id,\n",
    "                \"variant\": response.variant_name\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            print(f\"❌ Agent error: {e}\")\n",
    "            return {\n",
    "                \"response\": error_msg,\n",
    "                \"tool_calls\": [],\n",
    "                \"inference_id\": None,\n",
    "                \"variant\": None\n",
    "            }\n",
    "    \n",
    "    def show_history(self):\n",
    "        \"\"\"Display the conversation history.\"\"\"\n",
    "        print(\"\\n📜 Conversation History:\")\n",
    "        print(\"=\" * 40)\n",
    "        for i, msg in enumerate(self.conversation_history, 1):\n",
    "            role = msg['role']\n",
    "            content = msg['content']\n",
    "            print(f\"{i}. {role.title()}: {content}\")\n",
    "            if 'tool_calls' in msg:\n",
    "                for tool_call in msg['tool_calls']:\n",
    "                    print(f\"   🔧 Tool: {tool_call['name']}({tool_call['args']})\")\n",
    "        print(\"=\" * 40)\n",
    "\n",
    "# Create our agent\n",
    "agent = TensorZeroAgent(client)\n",
    "print(\"\\n✅ Agent ready! Available tools: calculator, get_weather, search_tensorzero_docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the Agent\n",
    "\n",
    "Let's test our agent with various tasks that require tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 Test 1: Math Calculation\n",
      "👤 User: What is 234 multiplied by 567?\n",
      "🔧 Used tools: 1\n",
      "   📌 calculator: {'expression': '234 * 567'}\n",
      "📝 Inference: 0198f364-878b-7f21-b8f4-73741beabffc...\n",
      "\n",
      "🌤️  Test 2: Weather Query\n",
      "👤 User: What's the weather like in Tokyo?\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 159\n",
      "\n",
      "📚 Test 3: Documentation Search\n",
      "👤 User: How does feedback work in TensorZero?\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 159\n",
      "\n",
      "🔄 Test 4: Multi-step Task\n",
      "👤 User: Calculate 150 USD in GBP at 0.79 exchange rate, and tell me the weather in London.\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 159\n",
      "\n",
      "✅ All tests completed!\n",
      "📊 Total inferences: 1\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Math calculation\n",
    "print(\"🧮 Test 1: Math Calculation\")\n",
    "result1 = agent.chat(\"What is 234 multiplied by 567?\")\n",
    "\n",
    "# Test 2: Weather query\n",
    "print(\"\\n🌤️  Test 2: Weather Query\")\n",
    "result2 = agent.chat(\"What's the weather like in Tokyo?\")\n",
    "\n",
    "# Test 3: Documentation search\n",
    "print(\"\\n📚 Test 3: Documentation Search\")\n",
    "result3 = agent.chat(\"How does feedback work in TensorZero?\")\n",
    "\n",
    "# Test 4: Multi-step task\n",
    "print(\"\\n🔄 Test 4: Multi-step Task\")\n",
    "result4 = agent.chat(\"Calculate 150 USD in GBP at 0.79 exchange rate, and tell me the weather in London.\")\n",
    "\n",
    "print(\"\\n✅ All tests completed!\")\n",
    "print(f\"📊 Total inferences: {len([r for r in [result1, result2, result3, result4] if r['inference_id']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Observability\n",
    "\n",
    "Let's explore how TensorZero tracks and observes agent interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📜 Agent Conversation History\n",
      "\n",
      "📜 Conversation History:\n",
      "========================================\n",
      "1. User: What is 234 multiplied by 567?\n",
      "2. Assistant: I need to use a tool to help you.\n",
      "   🔧 Tool: calculator({'expression': '234 * 567'})\n",
      "3. User: What's the weather like in Tokyo?\n",
      "4. User: How does feedback work in TensorZero?\n",
      "5. User: Calculate 150 USD in GBP at 0.79 exchange rate, and tell me the weather in London.\n",
      "========================================\n",
      "\n",
      "📊 Collecting Agent Feedback\n",
      "------------------------------\n",
      "✅ Feedback submitted: 0.95/1.0 - Perfect calculation!\n",
      "\n",
      "🌐 View agent interactions in TensorZero UI: http://localhost:4000\n",
      "📈 Check metrics and performance data in the dashboard\n"
     ]
    }
   ],
   "source": [
    "# Check agent conversation history\n",
    "print(\"📜 Agent Conversation History\")\n",
    "agent.show_history()\n",
    "\n",
    "# Collect some feedback\n",
    "print(\"\\n📊 Collecting Agent Feedback\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Simulate user feedback\n",
    "feedback_data = [\n",
    "    {\"inference_id\": result1.get(\"inference_id\"), \"rating\": 0.95, \"helpful\": True, \"comment\": \"Perfect calculation!\"},\n",
    "    {\"inference_id\": result2.get(\"inference_id\"), \"rating\": 0.8, \"helpful\": True, \"comment\": \"Weather info was useful\"},\n",
    "    {\"inference_id\": result3.get(\"inference_id\"), \"rating\": 0.9, \"helpful\": True, \"comment\": \"Good documentation search\"},\n",
    "    {\"inference_id\": result4.get(\"inference_id\"), \"rating\": 0.85, \"helpful\": True, \"comment\": \"Handled multiple tools well\"}\n",
    "]\n",
    "\n",
    "for feedback in feedback_data:\n",
    "    if feedback[\"inference_id\"]:\n",
    "        try:\n",
    "            # Submit feedback metrics\n",
    "            client.feedback(\n",
    "                metric_name=\"user_rating\",\n",
    "                inference_id=feedback[\"inference_id\"],\n",
    "                value=feedback[\"rating\"]\n",
    "            )\n",
    "            client.feedback(\n",
    "                metric_name=\"helpful\",\n",
    "                inference_id=feedback[\"inference_id\"],\n",
    "                value=feedback[\"helpful\"]\n",
    "            )\n",
    "            print(f\"✅ Feedback submitted: {feedback['rating']}/1.0 - {feedback['comment']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Feedback submission failed: {e}\")\n",
    "\n",
    "print(\"\\n🌐 View agent interactions in TensorZero UI: http://localhost:4000\")\n",
    "print(\"📈 Check metrics and performance data in the dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Performance Analysis\n",
    "\n",
    "Let's analyze how our agent performs across different types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 TensorZero Agent initialized\n",
      "🏃 Running Agent Benchmark (5 test cases)\n",
      "==================================================\n",
      "\n",
      "🧪 Test 1/5: Math\n",
      "Query: Calculate the compound interest on $1000 at 5% annual rate for 3 years\n",
      "❌ Failed: 1.5s, Error: 'UUID' object is not subscriptable...\n",
      "\n",
      "🧪 Test 2/5: Weather\n",
      "Query: What's the weather forecast for Paris?\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 199\n",
      "✅ Success: 0.13s, 0 tools, 177 chars\n",
      "\n",
      "🧪 Test 3/5: Documentation\n",
      "Query: How do I set up variants in TensorZero?\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 199\n",
      "✅ Success: 0.13s, 0 tools, 177 chars\n",
      "\n",
      "🧪 Test 4/5: Multi-tool\n",
      "Query: If it's sunny in Miami, calculate how many hours of sunlight that would be if we get 65% of maximum possible (12 hours)\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 199\n",
      "✅ Success: 0.13s, 0 tools, 177 chars\n",
      "\n",
      "🧪 Test 5/5: Conversational\n",
      "Query: Tell me about TensorZero and why it's useful for LLM applications\n",
      "❌ Agent error: Failed to deserialize JSON to tensorzero::client_input::ClientInput: messages[1].tool_calls: unknown field `tool_calls`, expected `role` or `content` at line 1 column 199\n",
      "✅ Success: 0.13s, 0 tools, 177 chars\n",
      "\n",
      "📊 Benchmark Results Summary\n",
      "========================================\n",
      "               success     duration_seconds     tool_calls response_length\n",
      "                 count sum             mean std       mean            mean\n",
      "category                                                                  \n",
      "Conversational       1   0             0.13 NaN        0.0           177.0\n",
      "Documentation        1   0             0.13 NaN        0.0           177.0\n",
      "Math                 1   0             1.50 NaN        0.0             0.0\n",
      "Multi-tool           1   0             0.13 NaN        0.0           177.0\n",
      "Weather              1   0             0.13 NaN        0.0           177.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def benchmark_agent(test_cases: List[Dict], agent_instance) -> pd.DataFrame:\n",
    "    \"\"\"Benchmark the agent across different types of queries.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"🏃 Running Agent Benchmark ({len(test_cases)} test cases)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        query = test_case[\"query\"]\n",
    "        category = test_case[\"category\"]\n",
    "        expected_tools = test_case.get(\"expected_tools\", [])\n",
    "        \n",
    "        print(f\"\\n🧪 Test {i}/{len(test_cases)}: {category}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Run agent\n",
    "            result = agent_instance.chat(query, show_details=False)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            duration = round(end_time - start_time, 2)\n",
    "            \n",
    "            # Analyze result\n",
    "            success = result[\"inference_id\"] is not None\n",
    "            tool_count = len(result[\"tool_calls\"])\n",
    "            response_length = len(result[\"response\"])\n",
    "            \n",
    "            results.append({\n",
    "                \"test_case\": i,\n",
    "                \"category\": category,\n",
    "                \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n",
    "                \"success\": success,\n",
    "                \"duration_seconds\": duration,\n",
    "                \"tool_calls\": tool_count,\n",
    "                \"response_length\": response_length,\n",
    "                \"inference_id\": result[\"inference_id\"][:10] + \"...\" if result[\"inference_id\"] else None\n",
    "            })\n",
    "            \n",
    "            print(f\"✅ Success: {duration}s, {tool_count} tools, {response_length} chars\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            end_time = time.time()\n",
    "            duration = round(end_time - start_time, 2)\n",
    "            \n",
    "            results.append({\n",
    "                \"test_case\": i,\n",
    "                \"category\": category,\n",
    "                \"query\": query[:50] + \"...\" if len(query) > 50 else query,\n",
    "                \"success\": False,\n",
    "                \"duration_seconds\": duration,\n",
    "                \"tool_calls\": 0,\n",
    "                \"response_length\": 0,\n",
    "                \"inference_id\": None,\n",
    "                \"error\": str(e)[:50]\n",
    "            })\n",
    "            \n",
    "            print(f\"❌ Failed: {duration}s, Error: {str(e)[:50]}...\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"category\": \"Math\",\n",
    "        \"query\": \"Calculate the compound interest on $1000 at 5% annual rate for 3 years\",\n",
    "        \"expected_tools\": [\"calculator\"]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Weather\", \n",
    "        \"query\": \"What's the weather forecast for Paris?\",\n",
    "        \"expected_tools\": [\"get_weather\"]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Documentation\",\n",
    "        \"query\": \"How do I set up variants in TensorZero?\",\n",
    "        \"expected_tools\": [\"search_tensorzero_docs\"]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Multi-tool\",\n",
    "        \"query\": \"If it's sunny in Miami, calculate how many hours of sunlight that would be if we get 65% of maximum possible (12 hours)\",\n",
    "        \"expected_tools\": [\"get_weather\", \"calculator\"]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Conversational\",\n",
    "        \"query\": \"Tell me about TensorZero and why it's useful for LLM applications\",\n",
    "        \"expected_tools\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create fresh agent for benchmarking\n",
    "benchmark_agent_instance = TensorZeroAgent(client)\n",
    "benchmark_results = benchmark_agent(test_cases, benchmark_agent_instance)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n📊 Benchmark Results Summary\")\n",
    "print(\"=\" * 40)\n",
    "summary = benchmark_results.groupby('category').agg({\n",
    "    'success': ['count', 'sum'],\n",
    "    'duration_seconds': ['mean', 'std'],\n",
    "    'tool_calls': 'mean',\n",
    "    'response_length': 'mean'\n",
    "}).round(2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Best Practices\n",
    "\n",
    "What we've learned about building agents with TensorZero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 TensorZero Agent Best Practices\n",
    "\n",
    "**1. Tool Configuration Approach:**\n",
    "- ✅ Configure tools in `tensorzero.toml` (TensorZero's way)\n",
    "- ❌ Don't try to send tools in request payloads (OpenAI's way)\n",
    "\n",
    "**2. Response Processing:**\n",
    "- ✅ Handle `ToolCall` objects from response content\n",
    "- ✅ Process both text and tool call content blocks\n",
    "- ✅ Use inference IDs for tracking and feedback\n",
    "\n",
    "**3. Agent Architecture:**\n",
    "- ✅ Keep conversation history for context\n",
    "- ✅ Handle tool call results properly\n",
    "- ✅ Implement proper error handling\n",
    "\n",
    "**4. Observability:**\n",
    "- ✅ Use TensorZero's built-in inference tracking\n",
    "- ✅ Submit feedback metrics for performance analysis\n",
    "- ✅ Monitor agent behavior in TensorZero UI\n",
    "\n",
    "### 🔧 Common Issues & Solutions\n",
    "\n",
    "**Error: `\"tools\" unknown field`** → Configure tools in `tensorzero.toml`, not requests\n",
    "**Error: `\"tool_calls\" unknown field`** → Handle TensorZero's `ToolCall` objects, not OpenAI format\n",
    "**No tool calls detected** → Check if tools are properly configured and function has tool access\n",
    "\n",
    "### 🚀 Production Considerations\n",
    "\n",
    "1. **Error Handling**: Robust fallback mechanisms for tool failures\n",
    "2. **Rate Limiting**: Manage API costs and quotas through TensorZero\n",
    "3. **Security**: Validate tool inputs and sanitize outputs\n",
    "4. **Monitoring**: Set up alerts for agent performance degradation\n",
    "5. **A/B Testing**: Use TensorZero variants to test different agent behaviors\n",
    "\n",
    "### 📊 Performance Benefits\n",
    "\n",
    "- **Unified API**: Single interface to multiple LLM providers\n",
    "- **Built-in Observability**: Automatic metrics collection and tracing\n",
    "- **Cost Optimization**: Automatic provider routing and caching\n",
    "- **Experimentation**: Easy A/B testing of different models/prompts\n",
    "- **Production Ready**: <1ms latency overhead, enterprise features\n",
    "\n",
    "---\n",
    "\n",
    "**🌐 TensorZero UI**: http://localhost:4000 - View all agent interactions, metrics, and performance data\n",
    "\n",
    "**📚 Next Steps**: Explore multi-agent systems, custom tool development, and advanced observability features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
