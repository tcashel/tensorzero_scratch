# Minimal working TensorZero configuration based on official quickstart

# Basic chat function with multiple provider variants
[functions.chat]
type = "chat"

# OpenAI variants
[functions.chat.variants.gpt4]
type = "chat_completion"
model = "openai::gpt-4"

[functions.chat.variants.gpt4_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini"

# Anthropic variants
[functions.chat.variants.claude3_opus]
type = "chat_completion"
model = "anthropic::claude-3-opus-20240229"

[functions.chat.variants.claude3_sonnet]
type = "chat_completion"
model = "anthropic::claude-3-sonnet-20240229"
max_tokens = 1000

[functions.chat.variants.claude3_haiku]
type = "chat_completion"
model = "anthropic::claude-3-haiku-20240307"

# xAI variants with latest models
[functions.chat.variants.grok3_mini]
type = "chat_completion"
model = "xai::grok-3-mini"

[functions.chat.variants.grok_code_fast]
type = "chat_completion"
model = "xai::grok-code-fast-1"

[functions.chat.variants.grok4]
type = "chat_completion"
model = "xai::grok-4-0709"

# Simple haiku generation function (from official example)
[functions.generate_haiku]
type = "chat"

[functions.generate_haiku.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini"

# Structured output function for sentiment analysis
[functions.analyze_sentiment]
type = "json"
system_schema = "functions/analyze_sentiment/system_schema.json"
output_schema = "functions/analyze_sentiment/output_schema.json"

[functions.analyze_sentiment.variants.gpt4_json]
type = "chat_completion"
model = "openai::gpt-4"
system_template = "functions/analyze_sentiment/system_template.minijinja"
json_mode = "strict"

[functions.analyze_sentiment.variants.claude_json]
type = "chat_completion"
model = "anthropic::claude-3-opus-20240229"
system_template = "functions/analyze_sentiment/system_template.minijinja"

[functions.analyze_sentiment.variants.grok3_json]
type = "chat_completion"
model = "xai::grok-3-mini"
system_template = "functions/analyze_sentiment/system_template.minijinja"